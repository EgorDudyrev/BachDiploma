{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix, csr_matrix, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from chord_rec_lib import delta_t #find_files, format_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chord_rec_lib import dnames\n",
    "\n",
    "HEAD_DIR = '..'\n",
    "for d in dnames:\n",
    "    dnames[d] = os.path.join(HEAD_DIR, dnames[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BB_DS_DIR': '../base_data/McGill-Billboard',\n",
       " 'BB_PARS_DS_DIR': '../base_data/billboard-2.0.1-lab/McGill-Billboard',\n",
       " 'CL_DS_DIR': '../base_data/chordlab',\n",
       " 'CSVS_DIR': '../csvs',\n",
       " 'RAW_SONGS_DIR': '../raw_songs',\n",
       " 'WAV_SONGS_DIR': '../wav_songs',\n",
       " 'SPECTRS_DIR': '../spectrs',\n",
       " 'SONGS_PARSED_DIR': '../songs_parsed',\n",
       " 'CHORDS_DIR': '../chords',\n",
       " 'X_DS_DIR': '../x_dataset'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fname(X_id):\n",
    "    return 'X_{}.npz'.format(X_id)\n",
    "def gen_fnames(X_ids):\n",
    "    return ['X_{}.npz'.format(X_id) for X_id in X_ids]\n",
    "\n",
    "def get_sample(X_id):\n",
    "    return load_npz(os.path.join(dnames['X_DS_DIR'], 'X_{}.npz'.format(X_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>fullname</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>chord_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>tone</th>\n",
       "      <th>majmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>906</td>\n",
       "      <td>E:(1)</td>\n",
       "      <td>119.730158</td>\n",
       "      <td>119.780948</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05079</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906</td>\n",
       "      <td>E:(1)</td>\n",
       "      <td>119.780948</td>\n",
       "      <td>119.831738</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05079</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>906</td>\n",
       "      <td>E:(1)</td>\n",
       "      <td>119.831738</td>\n",
       "      <td>119.882528</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05079</td>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>906</td>\n",
       "      <td>E:(1)</td>\n",
       "      <td>119.882528</td>\n",
       "      <td>119.933318</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05079</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>906</td>\n",
       "      <td>E:(1)</td>\n",
       "      <td>119.933318</td>\n",
       "      <td>119.984108</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05079</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id fullname   starttime     endtime  chord_id  duration  id tone  \\\n",
       "0      906    E:(1)  119.730158  119.780948       100   0.05079   0    E   \n",
       "1      906    E:(1)  119.780948  119.831738       100   0.05079   1    E   \n",
       "2      906    E:(1)  119.831738  119.882528       100   0.05079   2    E   \n",
       "3      906    E:(1)  119.882528  119.933318       100   0.05079   3    E   \n",
       "4      906    E:(1)  119.933318  119.984108       100   0.05079   4    E   \n",
       "\n",
       "  majmin  \n",
       "0      N  \n",
       "1      N  \n",
       "2      N  \n",
       "3      N  \n",
       "4      N  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ds = pd.read_csv(os.path.join(dnames['CSVS_DIR'], 'X_ds.csv'), index_col=0)\n",
    "X_ds = X_ds.fillna('N')\n",
    "X_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ds['majmin_enc'] = [line for line\n",
    "                      in OneHotEncoder(sparse=False).fit_transform(X_ds['majmin'].values.reshape(-1,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: 'majmin' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_ds.index = X_ds['majmin']\n",
    "idxs = X_ds.sample(n=2000, weights=X_ds.groupby('majmin').count()['id'])['id']\n",
    "X_ds.index = X_ds['id']\n",
    "#idxs = X_ds.sample(n=2000)['id']\n",
    "whole_ds = np.array([get_sample(i) for i in idxs])\n",
    "whole_ds = np.array([s.toarray().flatten() for s in whole_ds])\n",
    "X_train, y_train = whole_ds[:1500], X_ds.loc[idxs[:1500]]['majmin_enc']\n",
    "X_test, y_test = whole_ds[1500:], X_ds.loc[idxs[1500:]]['majmin_enc']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('train')\n",
    "for f in y_train.drop_duplicates():\n",
    "    print(f, (y_train==f).sum())\n",
    "print()\n",
    "print('test')\n",
    "for f in y_test.drop_duplicates():\n",
    "    print(f, (y_test==f).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense model. Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1290,)\n"
     ]
    }
   ],
   "source": [
    "s = whole_ds[0]\n",
    "print(s.toarray().flatten().shape)\n",
    "del s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(L.Dense(1024, activation='relu', input_dim=1290))\n",
    "model.add(L.Dense(256, activation='relu'))\n",
    "model.add(L.Dense(64, activation='relu'))\n",
    "model.add(L.Dense(3, activation='softmax', input_dim=64))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [y.reshape(-1,1) for y in y_train]\n",
    "y_train = np.concatenate(y_train).reshape(1500,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [y.reshape(-1,1) for y in y_test]\n",
    "y_test = np.concatenate(y_test).reshape(500,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 1s 493us/step - loss: 10.0132 - acc: 0.3387\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 1s 419us/step - loss: 9.9360 - acc: 0.3393\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 414us/step - loss: 9.9346 - acc: 0.3393\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 474us/step - loss: 9.9331 - acc: 0.3393\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 419us/step - loss: 9.9307 - acc: 0.3393\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 1s 422us/step - loss: 9.9299 - acc: 0.3393\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 1s 416us/step - loss: 9.9282 - acc: 0.3393\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 417us/step - loss: 9.9272 - acc: 0.3393\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 9.9262 - acc: 0.3393\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 1s 464us/step - loss: 9.9250 - acc: 0.3393\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 1s 476us/step - loss: 9.9242 - acc: 0.3393\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 516us/step - loss: 9.9236 - acc: 0.3393\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 505us/step - loss: 9.9228 - acc: 0.3393\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 608us/step - loss: 9.9222 - acc: 0.3393\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 463us/step - loss: 9.9217 - acc: 0.3393\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 686us/step - loss: 9.9212 - acc: 0.3393\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 9.9207 - acc: 0.3393\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 687us/step - loss: 9.9203 - acc: 0.3393\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 9.9200 - acc: 0.3393\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 626us/step - loss: 9.9196 - acc: 0.3393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09d40f0748>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 368us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.698609790802003, 0.3600000035762787]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly it's not so good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: 'majmin' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_ds.index = X_ds['majmin']\n",
    "idxs = X_ds.sample(n=2000, weights=X_ds.groupby('majmin').count()['id'])['id']\n",
    "X_ds.index = X_ds['id']\n",
    "#idxs = X_ds.sample(n=2000)['id']\n",
    "whole_ds = np.array([get_sample(i) for i in idxs])\n",
    "whole_ds = np.array([s.todense().reshape(129,10, 1) for s in whole_ds])\n",
    "X_train, y_train = whole_ds[:1500], X_ds.loc[idxs[:1500]]['majmin_enc']\n",
    "X_test, y_test = whole_ds[1500:], X_ds.loc[idxs[1500:]]['majmin_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 10)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# input: 129x10 images with 1 channels -> (129, 10, 1) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(L.Conv1D(10, (3), activation='relu', input_shape=(129, 10), padding='same'))\n",
    "model.add(L.Conv1D(32, (3), activation='relu', padding='same'))\n",
    "model.add(L.MaxPooling1D(pool_size=(2)))\n",
    "model.add(L.Dropout(0.25))\n",
    "model.add(L.Conv1D(64, (3), activation='relu', padding='same'))\n",
    "model.add(L.Conv1D(64, (3), activation='relu', padding='same'))\n",
    "model.add(L.MaxPooling1D(pool_size=(2)))\n",
    "model.add(L.Dropout(0.25))\n",
    "\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(256, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [X_train[i].reshape(129,10,1) for i in range(len(X_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1500, 129,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [y.reshape(-1,1) for y in y_train]\n",
    "y_train = np.concatenate(y_train).reshape(1500,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 10.0734 - acc: 0.3200\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9494 - acc: 0.3293\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9908 - acc: 0.3307\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9580 - acc: 0.3287\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9785 - acc: 0.3360\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9794 - acc: 0.3233\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9715 - acc: 0.3253\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9482 - acc: 0.3260\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9589 - acc: 0.3200\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.9682 - acc: 0.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0995ccb4e0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [y.reshape(-1,1) for y in y_test]\n",
    "y_test = np.concatenate(y_test).reshape(500,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 900us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.002817565917969, 0.3359999997615814]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
